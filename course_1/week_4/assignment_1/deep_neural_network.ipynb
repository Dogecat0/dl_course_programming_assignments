{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/wangzhicheng/opt/anaconda3/envs/dlcourse/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.22.2)\n",
      "Requirement already satisfied: h5py in /Users/wangzhicheng/opt/anaconda3/envs/dlcourse/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (3.6.0)\n",
      "Requirement already satisfied: matplotlib in /Users/wangzhicheng/opt/anaconda3/envs/dlcourse/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (3.5.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/wangzhicheng/opt/anaconda3/envs/dlcourse/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 3)) (4.31.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/wangzhicheng/opt/anaconda3/envs/dlcourse/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/wangzhicheng/opt/anaconda3/envs/dlcourse/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/wangzhicheng/opt/anaconda3/envs/dlcourse/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 3)) (3.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/wangzhicheng/opt/anaconda3/envs/dlcourse/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/wangzhicheng/opt/anaconda3/envs/dlcourse/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 3)) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/wangzhicheng/opt/anaconda3/envs/dlcourse/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 3)) (9.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/wangzhicheng/opt/anaconda3/envs/dlcourse/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 3)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from testCases import *\n",
    "from dnn_utils import sigmoid,sigmoid_backward,relu,relu_backward\n",
    "from public_tests import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 layer NN\n",
    "# Initialize parameters function\n",
    "def initialize_parameters(n_x,n_h,n_y):\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    W1 = np.random.randn(n_h,n_x)*0.01\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.rand(n_y,n_h)*0.01\n",
    "    b2 = np.zeros((n_y,1))\n",
    "\n",
    "    parameters = {'W1':W1, 'b1':b1, 'W2':W2, 'b2':b2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L layer NN\n",
    "# Initialize parameters function\n",
    "def initialize_parameters_deep(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims) \n",
    "\n",
    "    for l in range (1,L):\n",
    "        parameters['W'+str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*0.01\n",
    "        parameters['b'+str(l)] = np.zeros((layer_dims[l],1))\n",
    "\n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear forward function\n",
    "def linear_forward (A,W,b):\n",
    "    Z = np.dot(W,A) + b\n",
    "    cache = (A,W,b)\n",
    "    return Z,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear activation forward function\n",
    "def linear_activation_forward(A_prev,W,b,activation):\n",
    "    if activation == 'sigmoid':\n",
    "        Z,linear_cache = linear_forward(A_prev,W,b)\n",
    "        A,activation_cache = sigmoid(Z)\n",
    "    elif activation == 'relu':\n",
    "        Z,linear_cache = linear_forward(A_prev,W,b)\n",
    "        A,activation_cache = relu(Z)\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A,cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L layers forward function\n",
    "def L_model_forward(X,parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters)//2 # number of layers in the neural network\n",
    "    for l in range (1,L):\n",
    "         A_prev = A\n",
    "         A, cache = linear_activation_forward(A_prev,parameters['W'+str(l)],parameters['b'+str(l)],activation='relu')\n",
    "         caches.append(cache)\n",
    "\n",
    "    AL,cache = linear_activation_forward(A,parameters['W'+str(L)],parameters['b'+str(L)],activation='sigmoid')\n",
    "    caches.append(cache)\n",
    "    return AL,caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function\n",
    "def compute_cost(AL,Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = (-1/m)*(np.dot(Y,np.log(AL).T)+np.dot((1-Y),np.log(1-AL).T))\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear backward function\n",
    "def linear_backward(dZ,cache):\n",
    "    A_prev,W,b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = (1/m)*np.dot(dZ,A_prev.T)\n",
    "    db = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    return dA_prev,dW,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear activation backward function\n",
    "def linear_activation_backward(dA,cache,activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    if activation == 'relu':\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev,dW,db = linear_backward(dZ,linear_cache)\n",
    "\n",
    "    elif activation == 'sigmoid':\n",
    "        dZ = sigmoid_backward(dA,activation_cache)\n",
    "        dA_prev,dW,db = linear_backward(dZ,linear_cache)\n",
    "        \n",
    "    return dA_prev,dW,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L layers backward function\n",
    "def L_model_backward(AL,Y,caches):\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "\n",
    "    dAL = -(np.divide(Y,AL) - np.divide(1-Y,1-AL))\n",
    "\n",
    "    # Lth layer\n",
    "    current_cache = caches[L-1]\n",
    "    dA_prev_temp,dW_temp,db_temp = linear_activation_backward(dAL,current_cache,activation='sigmoid')\n",
    "    grads['dA'+str(L-1)] = dA_prev_temp\n",
    "    grads['dW'+str(L)] = dW_temp\n",
    "    grads['db'+str(L)] = db_temp\n",
    "\n",
    "    # Loop from l=L-2 to l=0\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp,dW_temp,db_temp = linear_activation_backward(grads['dA'+str(L-1)],current_cache,activation='relu')\n",
    "        grads['dA'+str(l)] = dA_prev_temp\n",
    "        grads['dW'+str(l+1)] = dW_temp\n",
    "        grads['db'+str(l+1)] = db_temp\n",
    "\n",
    "        return grads\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters function\n",
    "def update_parameters(params,grads,learning_rate):\n",
    "    parameters = params.copy()\n",
    "    L = len(parameters)//2\n",
    "\n",
    "    for l in range(L):\n",
    "        parameters['W'+str(l+1)] = parameters['W'+str(l+1)] - learning_rate*grads['dW'+str(l+1)]\n",
    "        parameters['b'+str(l+1)] = parameters['b'+str(l+1)] - learning_rate*grads['db'+str(l+1)]\n",
    "    \n",
    "    return parameters"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c755d7428ef2916a60a5fecbc4eac8419c923f04501f2411844dce09f16cfba"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('dlcourse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
